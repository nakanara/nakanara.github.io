# 파이썬 교육 4일차

* ML에서 추가적으로 필요한 요구사항, 왜 그런지에 대한 설명 및 원인  
  X_AI: 설명 가능한 기능


* CNN: 시각화 정보
* DL에서 판단하는 필터를 레이어라고 함, 뉴런 패턴에 따라 자동으로 계산
> DL은 형렬 곱, 각각의 항목에 의한 방향성

* 딥러닝 알고리즘 중 3가지
  
   https://ebbnflow.tistory.com/119  
   (NN:Neural Network 인간의 신경망 유사)
   CNN, RNN 뒷에는 DNN이 붙음, 결과를 판단하기 위해
  * DNN: Deep NN, 2차원정보, 표(엑셀) 
  * CNN: 이미지(눈), 사진
  * RNN: 시계열 데이터(귀), 주식, Recurrent 반복문


* 랜덤포레스트, 앙상블모델이 가장 우수

* 인공지능 챗봇이 힘든이유?

  * 컴퓨터는 상식을 배울수 없기 때문에 챗봇은 힘듬
  * 컴퓨터는 숫자만을 인지하고 학습하는데 상식은 숫자화 할 수 없음
  * 컴퓨터는 문맥을 이해못함, 대화 도중에 '이것', 같은 단어의 내용을 유추할 수 없음
  * 챗봇은 기억영역이 없기 때문에 DB접속 등 외부적 요인이 필요 함


GPU를 이용한 DL은 Nvida만 가능함, GPU에 연산가능한 기능이 있어서
DL에서 Tensorflow가 표준으로 가는 추세, 경쟁 솔루션 파이토치

* ZeroPadding: 0채움
* Convolution: 필터를 넣어서 값을 찾아라

# GPU 설치 여부 확인 방법

작업 관리자 -> 성능 -> GPU -> Inter(R)은 불가, NVdia만 가능(최신 GPU)
GTX10xx
RTX20xx 
RT30xx

GPU가 가능한 경우 pip 로 설치하는 것보다는 conda로 설치하는 것이 유리
$ pip install tensflow-gpu
$ conda install tensflow-gpu -y 

GPU가 불가능한 경우(CPU 버전으로 설치)
$ pip install tensflow
$ conda install tensflow -y 

* 버전 명시하는 경우
$ pip install tensflow==2.2
$ conda install tensflow==2.2 -y 


# 불균형데이터

불균형 데이터는 잘못 학습될 수 있다. 데이터의 균형이 필요

암환자 기준
정상: 900
암환자: 100

전부 정상이라고 해도 정확도는 100/900 -> 90% 임
데이터 량을 균형화 해야 함


# ML 설계

DL과 karas 사용법은 동일하며, 모델 설계 부분만 사용법이 다르다.
레이어를 Dense라고 함

* DL의 CNN의 필터가 많이 들어갈경우 원본이 사라지는 현상 때문에 activation='relu' 사용
  배너싱그레디언트
  FC: Fully Connected 풀리커넥티드 - 전체 연결 후 판단 

* activation
  * softmax: 각각의 경우의수를 돌려주고, 그 합을 구했을 때 1이 되도록 (확률)
  * sigmoid: True, False 로 선택할 경우
  * 값만 받을 경우 그냥 받음
  * relu: 원봉 이미지가 사라지는 현상 때문에

* Sequential: 뇌 전체 
* optimizer 성능 항샹 주로 Adam 많이 사용
  * lr: 러닝 메이트, 학습할내용이많다면 큰 숫자
  * categorycal : 분류, 합은 1, 중복될 수 없다
  * crossntropy: 합은 1로 이루어지며, 일어날일이 일어나는 것
  * ntropy: 열역학의 2법칙, 무질서, 놀람의 정도, 잘못된 값이 왔을 때는 큰 값을 돌려주며, 일반적인 값이 왔을 경우에는 놀라지 않는다. 적절한 수치로 돌려줌, 잘못된 값이 온경우 큰 수치 돌려줌, 일반적인 값이 온경우에는 작은 값을 돌려준댜, 배달률과 유사
  * 


SV 알고리즘은 큰 값에 영향을 받음. 학습이 잘 안됨 -5 ~ 5 가 적절합

학습이 안되어서 LELU 로 변경
GD -> SGD로 변경

LSTM: Long Short Term Memory 단기 기억을 해둠. RNN 개선 버전

```python

Danse(4096) # 2n승이므로
model.add(Dropout(0.5)) # 50% 날림, 전체를 기억하지 못하도록
```


VGG: 많이 사용
GoogleNet
ResNet: MS 에서 만듬

FC: DNN. Fully connected 전체 연결 영역

### 그림 설명

파란색은 필터, 흰색은 그림을 반으로 줄임

* CONV3-64 -> 3*3 의 필터 64장 
* POOL2 -> 이미지 반으로 줄임 


필터를 사용하는 이유: 
이미지는 RGB로 3개의 채널을 가지고 있음
1000*1000 이미지일 경우 
1000*1000*3(rgb) -> 의 경우 메모리를 많이 사용하여 DNN 사용 안함 - 이미지의 경우

* MaxPooling: 2*2 셀에서 가장 큰 수만 남겨서 축소한다. 선명한 정보만 남겨서, 판단과 학습은 쉬워지고 노이즈가 줄어든다.
* averagePooling: 2*2 셀에서 평균으로 보내는 경우가 있는데 이미지가 뭉개지는 현상 발생

* Fully Connected Layout (DNN)
필터가 없으면 DNN, 필터 후 DNN이면 CNN

osftmax로 합이 1인 각각의 항률이 나타남, 그중 높은 값이 답임

Value - 값을 그냥 받는다


## DL 관련 Tools 설치(중요)

* keras 설치 (자동으로 Tensorflow 설치)

>  시작 -> Anaconda3 -> Anaconda Prompt   
>  $ conda install keras==2.2.4   
>  y 누르고 설치  


# 참고
* https://ebbnflow.tistory.com/119
* https://teachablemachine.withgoogle.com/ 구글에서 만든 머신러닝 
* 